{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOjAvYwVtvKi1bHI25n31V0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["This notebook describes a classifier for whether the Turkish “de/da” and “ki” suffixes should be\n","separated or not.\n","\n","For example, in “Öğrenciler de geldi” it is separated, but in “Öğrencilerde gelişme\n","var.” it is not separated."],"metadata":{"id":"xLfzx5DEhRGH"}},{"cell_type":"markdown","source":["# Imports\n","*   Import necessary libraries\n","\n"],"metadata":{"id":"xQDZBkoOia6l"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"2vJUt93sg0ns","executionInfo":{"status":"ok","timestamp":1706520667750,"user_tz":-180,"elapsed":11331,"user":{"displayName":"asuman sare","userId":"06409084491818674660"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import pad_sequences\n","from sklearn.model_selection import train_test_split\n","import numpy as np  # Import NumPy for array manipulation"]},{"cell_type":"markdown","source":["# Providing the Data"],"metadata":{"id":"VpIZzDRnjbnm"}},{"cell_type":"code","source":["# Read the annotated file\n","with open(\"annotated_sentences_for_de.txt\", \"r\", encoding=\"utf-8\") as file:\n","    lines = file.readlines()\n","\n","# Data pre-processing\n","sentences = []\n","labels = []\n","\n","for line in lines:\n","    parts = line.strip().split()\n","    if len(parts) >= 2:\n","        sentences.append(parts[0])\n","        labels.append(parts[-1])\n","\n","# Encode labels into numerical values\n","label_mapping = {\"O\": 0, \"B-ERR\": 1}\n","labels = [label_mapping[label] for label in labels]\n","\n","# Tokenization and padding\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(sentences)\n","total_words = len(tokenizer.word_index) + 1\n","\n","sequences = tokenizer.texts_to_sequences(sentences)\n","padded_sequences = pad_sequences(sequences)\n","\n","# Convert labels to numpy arrays\n","labels = np.array(labels)\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n"],"metadata":{"id":"7QsHRkoMiQ9Y","executionInfo":{"status":"ok","timestamp":1706520680172,"user_tz":-180,"elapsed":768,"user":{"displayName":"asuman sare","userId":"06409084491818674660"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Define and Compile the Neural Network"],"metadata":{"id":"-3F_750Divtp"}},{"cell_type":"code","source":["batch_size = 16\n","learning_rate = 0.2\n","hidden_size = 100\n","\n","# Model architecture with optimized hyperparameters\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=total_words, output_dim=16, input_length=len(padded_sequences[0])),\n","    tf.keras.layers.LSTM(hidden_size, return_sequences=True),  # Use return_sequences=True for stacking LSTM layers\n","    tf.keras.layers.LSTM(hidden_size),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model with the chosen learning rate\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"5GfzvXg0Zc4e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training the Neural Network\n","Tooks approximately 40 minutes for 20 epoch, 120 second for each epoch (on T4 GPU)"],"metadata":{"id":"skQ2b8ksjh1a"}},{"cell_type":"code","source":["# Train the model with the chosen batch size\n","model.fit(X_train, y_train, epochs=20, batch_size=batch_size, validation_data=(X_val, y_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKXDuiRYrJMY","executionInfo":{"status":"ok","timestamp":1706534198899,"user_tz":-180,"elapsed":2192005,"user":{"displayName":"asuman sare","userId":"06409084491818674660"}},"outputId":"41e12a8f-d5a6-434b-e57b-f523c1c4b56a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","14313/14313 [==============================] - 110s 7ms/step - loss: 0.1468 - accuracy: 0.9712 - val_loss: 0.1904 - val_accuracy: 0.9756\n","Epoch 2/20\n","14313/14313 [==============================] - 105s 7ms/step - loss: 0.1270 - accuracy: 0.9728 - val_loss: 0.1058 - val_accuracy: 0.9755\n","Epoch 3/20\n","14313/14313 [==============================] - 115s 8ms/step - loss: 0.1422 - accuracy: 0.9730 - val_loss: 0.0750 - val_accuracy: 0.9696\n","Epoch 4/20\n","14313/14313 [==============================] - 104s 7ms/step - loss: 0.1306 - accuracy: 0.9752 - val_loss: 0.1788 - val_accuracy: 0.9755\n","Epoch 5/20\n","14313/14313 [==============================] - 115s 8ms/step - loss: 0.1524 - accuracy: 0.9755 - val_loss: 0.1584 - val_accuracy: 0.9756\n","Epoch 6/20\n","14313/14313 [==============================] - 105s 7ms/step - loss: 0.1497 - accuracy: 0.9750 - val_loss: 0.1160 - val_accuracy: 0.9756\n","Epoch 7/20\n","14313/14313 [==============================] - 105s 7ms/step - loss: 0.1514 - accuracy: 0.9752 - val_loss: 0.1454 - val_accuracy: 0.9756\n","Epoch 8/20\n","14313/14313 [==============================] - 105s 7ms/step - loss: 0.1559 - accuracy: 0.9755 - val_loss: 0.1954 - val_accuracy: 0.9756\n","Epoch 9/20\n","14313/14313 [==============================] - 104s 7ms/step - loss: 0.1430 - accuracy: 0.9758 - val_loss: 0.1329 - val_accuracy: 0.9755\n","Epoch 10/20\n","14313/14313 [==============================] - 105s 7ms/step - loss: 0.1574 - accuracy: 0.9741 - val_loss: 0.1089 - val_accuracy: 0.9756\n","Epoch 11/20\n","14313/14313 [==============================] - 115s 8ms/step - loss: 0.1457 - accuracy: 0.9738 - val_loss: 0.3607 - val_accuracy: 0.9756\n","Epoch 12/20\n","14313/14313 [==============================] - 114s 8ms/step - loss: 0.1639 - accuracy: 0.9738 - val_loss: 0.1430 - val_accuracy: 0.9756\n","Epoch 13/20\n","14313/14313 [==============================] - 107s 7ms/step - loss: 0.1767 - accuracy: 0.9748 - val_loss: 0.1206 - val_accuracy: 0.9756\n","Epoch 14/20\n","14313/14313 [==============================] - 110s 8ms/step - loss: 0.1721 - accuracy: 0.9746 - val_loss: 0.1230 - val_accuracy: 0.9756\n","Epoch 15/20\n","14313/14313 [==============================] - 111s 8ms/step - loss: 0.1698 - accuracy: 0.9751 - val_loss: 0.2918 - val_accuracy: 0.9756\n","Epoch 16/20\n","14313/14313 [==============================] - 109s 8ms/step - loss: 0.1733 - accuracy: 0.9752 - val_loss: 0.1159 - val_accuracy: 0.9756\n","Epoch 17/20\n","14313/14313 [==============================] - 107s 7ms/step - loss: 0.1692 - accuracy: 0.9753 - val_loss: 0.1295 - val_accuracy: 0.9756\n","Epoch 18/20\n","14313/14313 [==============================] - 107s 8ms/step - loss: 0.1696 - accuracy: 0.9751 - val_loss: 0.1467 - val_accuracy: 0.9756\n","Epoch 19/20\n","14313/14313 [==============================] - 109s 8ms/step - loss: 0.1695 - accuracy: 0.9754 - val_loss: 0.1865 - val_accuracy: 0.9756\n","Epoch 20/20\n","14313/14313 [==============================] - 108s 8ms/step - loss: 0.1618 - accuracy: 0.9736 - val_loss: 0.1419 - val_accuracy: 0.9755\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78bf1e5c9c60>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# Save the Model"],"metadata":{"id":"YtKiJEHUUh3f"}},{"cell_type":"code","source":["import pickle\n","\n","# Specify the path where you want to save the model\n","model_save_path = \"/content/custom_model/model.h5\"\n","\n","# Save the model\n","model.save(model_save_path)\n","\n","# Optionally, you can also save the tokenizer if you need it for later use\n","tokenizer_save_path = \"/content/custom_model/tokenizer.pickle\"\n","with open(tokenizer_save_path, 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNzvZw3lUkB7","executionInfo":{"status":"ok","timestamp":1706534205953,"user_tz":-180,"elapsed":440,"user":{"displayName":"asuman sare","userId":"06409084491818674660"}},"outputId":"ddd5e8d1-aa18-4ba2-b1d3-5e2069239b6c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"markdown","source":["# Test the Model"],"metadata":{"id":"p4NafOnvZmjV"}},{"cell_type":"code","source":["from keras.models import load_model\n","\n","# Load the model\n","loaded_model = load_model(model_save_path)\n","\n","# Optionally, load the tokenizer\n","with open(tokenizer_save_path, 'rb') as handle:\n","    loaded_tokenizer = pickle.load(handle)\n","\n","# Use the trained model for predictions\n","new_sentence = \"Emekli Albay Yıldırım Taşyumruk birazda mesleği gereği ömrü boyu sert ve otoriter bir baba olmuştur.\"\n","print(f\"Input Sentence: {new_sentence}\")\n","new_sequence = loaded_tokenizer.texts_to_sequences([new_sentence])\n","new_padded_sequence = pad_sequences(new_sequence, maxlen=len(padded_sequences[0]))\n","\n","# Assuming the model.predict() returns a single value\n","predicted_value = loaded_model.predict(new_padded_sequence)[0][0]\n","\n","# Set a threshold (e.g., 0.5)\n","threshold = 0.0034501181318774e-06\n","\n","# Classify based on the threshold\n","predicted_class = \"Error DETECTED! It is a conjunction! \" if predicted_value > threshold else \"Correct Sentence :)\"\n","\n","print(f\"Predicted class: {predicted_class}\")\n","# print(f\"Predicted value: {predicted_value}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3aB41yBNtw11","executionInfo":{"status":"ok","timestamp":1706542886646,"user_tz":-180,"elapsed":1901,"user":{"displayName":"asuman sare","userId":"06409084491818674660"}},"outputId":"45962398-c7fe-4806-b1ca-d4ecd0de56eb"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Sentence: Emekli Albay Yıldırım Taşyumruk birazda mesleği gereği ömrü boyu sert ve otoriter bir baba olmuştur.\n","1/1 [==============================] - 1s 942ms/step\n","Predicted class: Error DETECTED! It is a conjunction! \n"]}]},{"cell_type":"code","source":["from keras.models import load_model\n","\n","# Load the model\n","loaded_model = load_model(model_save_path)\n","\n","# Optionally, load the tokenizer\n","with open(tokenizer_save_path, 'rb') as handle:\n","    loaded_tokenizer = pickle.load(handle)\n","\n","\n","# Load and predict on sentences from \"test_sentences_de.txt\"\n","test_sentences_path = \"test_sentences_de.txt\"\n","\n","with open(test_sentences_path, 'r', encoding='utf-8') as file:\n","    test_sentences = file.readlines()\n","\n","# Set a threshold (e.g., 0.0034501181318774e-06)\n","threshold = 0.00119469075778033584\n","\n","for sentence in test_sentences:\n","    print(f\"Input sentence: {sentence}\")\n","    # Tokenize the sentence\n","    tokens = sentence.split()\n","\n","    # Predict for each word in the sentence\n","    for token in tokens:\n","        if token.endswith((\"de\", \"da\", \"te\", \"ta\")):\n","            print(f\"Inspecting Word: {token}\")\n","            # Tokenize and pad the word\n","            new_sequence = loaded_tokenizer.texts_to_sequences([token])\n","            new_padded_sequence = pad_sequences(new_sequence, maxlen=len(padded_sequences[0]))\n","\n","            # Predict using the loaded model\n","            predicted_value = loaded_model.predict(new_padded_sequence)[0][0]  # Extract the value from the numpy array\n","            print(f\"Predicted value: {predicted_value}\")\n","\n","            # Classify based on the threshold\n","            if predicted_value > threshold:\n","                print(f\"Suspicious Word: {token}\")\n","\n","    # Print the completed sentence\n","    print(\"===\")  # Separate output for each sentence\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"MRIpnsYAqqdy","executionInfo":{"status":"error","timestamp":1706542633379,"user_tz":-180,"elapsed":1386,"user":{"displayName":"asuman sare","userId":"06409084491818674660"}},"outputId":"f9c7cd5e-22ca-4cb0-e512-9695225d5725"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Input sentence: Evde yağ kalmamış.\n","\n","Inspecting Word: Evde\n"]},{"output_type":"error","ename":"KeyError","evalue":"'Evde'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-1d92a2534925>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Predict using the loaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mpredicted_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloaded_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted value: {predicted_value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Evde'"]}]}]}